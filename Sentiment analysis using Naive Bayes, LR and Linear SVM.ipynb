{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full_test.txt', 'full_train.txt']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/movie_data/movie_data\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "440890c4325dfc2afdb0e2d2513c373ff9f523e4"
   },
   "outputs": [],
   "source": [
    "reviews_train = []\n",
    "for line in open('../input/movie_data/movie_data/full_train.txt', 'r'):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open('../input/movie_data/movie_data/full_test.txt', 'r'):\n",
    "    \n",
    "    reviews_test.append(line.strip())\n",
    "    \n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "56e3ed672c5e10feb0420a9d5a3f165fee6757ee"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd0c4b24f8dd80147a3c532aaad0354e227c1c81"
   },
   "outputs": [],
   "source": [
    "baseline_vectorizer = CountVectorizer(binary=True)\n",
    "baseline_vectorizer.fit(reviews_train_clean)\n",
    "print(\"Size of dictionary: \", len(baseline_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", baseline_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c4382f0f979775bffe64eb3a0fd4e380e0f48a2"
   },
   "outputs": [],
   "source": [
    "X_baseline = baseline_vectorizer.transform(reviews_train_clean)\n",
    "X_test_baseline = baseline_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ecf949a36d6f7a1934416203c77d6d96ebc6e21"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_baseline, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92ad90e62dbd4614d9c0987fd31d0fe82e9106f6"
   },
   "outputs": [],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test_baseline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f8f7d6b031fcbe53e38fbfdbcafc7c7153097b4"
   },
   "source": [
    "**Remove stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "001b133d89794bcb0234dac8c377806716585002"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e03b8f1679d1e312d996dcb21a784838d91543d1"
   },
   "outputs": [],
   "source": [
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "no_stop_words_test = remove_stop_words(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "616508ae90c6ddfe76f7405b7366d7de5a55308a"
   },
   "outputs": [],
   "source": [
    "stopword_vectorizer = CountVectorizer(binary=True)\n",
    "stopword_vectorizer.fit(no_stop_words_train)\n",
    "print(\"Size of dictionary: \", len(stopword_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", stopword_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f617964395eec60b85ee23eab8c536488f6ec349"
   },
   "outputs": [],
   "source": [
    "X = stopword_vectorizer.transform(no_stop_words_train)\n",
    "X_test = stopword_vectorizer.transform(no_stop_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fe72315991aaa0e32d78ce8dffcae192136fa6a"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "130f1422884152e4e665baafb460e633dc8c5873"
   },
   "outputs": [],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b824e3f534b06636fba77dd6f03b9aecd151a1d"
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        stopword_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b03fbf99af5e47b9a94297456d2b9230a850686"
   },
   "source": [
    "**Lemmatization**\n",
    "https://www.datacamp.com/community/tutorials/stemming-lemmatization-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c4db0d273a3a1c8f378130a5e79eaaa32fb3d35"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def get_lemmatized_text(corpus):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d824e25eea5788f3c5b91acaa7767e55ff3a24a9"
   },
   "outputs": [],
   "source": [
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5d93a1407466f25ff5c9e14e3b3ab6f0e6f4326"
   },
   "outputs": [],
   "source": [
    "lemmatize_vectorizer = CountVectorizer(binary=True)\n",
    "lemmatize_vectorizer.fit(lemmatized_reviews_train)\n",
    "print(\"Size of dictionary: \", len(lemmatize_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", lemmatize_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6bd3e5aa5c66b7de8a9382751196abf498797795"
   },
   "outputs": [],
   "source": [
    "X = lemmatize_vectorizer.transform(lemmatized_reviews_train)\n",
    "X_test = lemmatize_vectorizer.transform(lemmatized_reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "44511cc9b69eda0fd5035791c872df22add34a21"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a676c42185b4b7f04cded238d0c142ffbe41883"
   },
   "outputs": [],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f89a7c7c8455f88113bab88d47543c0e28dfcbe6"
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        lemmatize_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf94883bdf5c28de2a42d3da8b26c9aecb3624e5"
   },
   "source": [
    "**Stemming**\n",
    "https://www.datacamp.com/community/tutorials/stemming-lemmatization-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f9dfe3572ab2e1781c9ec13477871b4b9f695be"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def get_stemmed_text(corpus):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "268804b825dc86597e80603034028a6323c1a721"
   },
   "outputs": [],
   "source": [
    "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02b45ccaafe11cb9156b7374ecf5d8ec9137e96b"
   },
   "outputs": [],
   "source": [
    "stemm_vectorizer = CountVectorizer(binary=True)\n",
    "stemm_vectorizer.fit(stemmed_reviews_train)\n",
    "print(\"Size of dictionary: \", len(stemm_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", stemm_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c1023addd308e8f2d5c9fc066477657bb64dc97"
   },
   "outputs": [],
   "source": [
    "X = stemm_vectorizer.transform(stemmed_reviews_train)\n",
    "X_test = stemm_vectorizer.transform(stemmed_reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e749dcb80210e9b929e727b9f6ad59d2731fb90f"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "963a9cf89ce5d2e788657220e7335fe81aeee3b6"
   },
   "outputs": [],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fab870c9fbb02dd503883f206a7e4960a88e3cc"
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        stemm_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "140d85693fd55aed4c2f6f4c6aca3cc349ea36ff"
   },
   "source": [
    "**Using n-grams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ce2b40c4b5fe7f27512cb10ad3799c7e2d0e8d0"
   },
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "print(\"Size of dictionary: \", len(ngram_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", ngram_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "779f5e05b188a152d69ade647c397b3a99043359"
   },
   "outputs": [],
   "source": [
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fab6ba04b1d860801ac10f06a7a5332c7a671b71"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "327714a5bc853501db58d4f247e65301927d1bcf"
   },
   "outputs": [],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8004f72ed3fd236ab68105625dbf7a05c0d326b"
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        ngram_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a47d7a4a136479bb079127ead0d580a258ec9389"
   },
   "source": [
    "**TF-IDF (term frequency-inverse term frequency)**\n",
    "https://buhrmann.github.io/tfidf-analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93106652011b51f0be1654c6f70831a272b3820b"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', analyzer='word', ngram_range=(1, 2))\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "print(\"Size of dictionary: \", len(tfidf_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57591329558be2bd3ecb8c0a86b93037757e67bb"
   },
   "outputs": [],
   "source": [
    "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_test = tfidf_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c1aa539a1eeba9a5e46ca70c36bb402e8531dd8"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lr = LogisticRegression(C=i)\n",
    "    lr.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a17696a9cb6f5f74c61aa6dee87f377ad88ad113"
   },
   "outputs": [],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LogisticRegression(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96a01432e4cdc87d00f7e0bf4a68b83671278441"
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        tfidf_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "80b188699fef8f6736345d5683877f12bad466ea"
   },
   "source": [
    "**Using linear Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fcc5859c4b1b54a346e5bd2fac0dcbb8c3ff6824"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc_ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "lsvc_ngram_vectorizer.fit(reviews_train_clean)\n",
    "print(\"Size of dictionary: \", len(lsvc_ngram_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", lsvc_ngram_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "538244f0ff4bbf7887e98f6ea466c5f650ce41b1"
   },
   "outputs": [],
   "source": [
    "X = lsvc_ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = lsvc_ngram_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58f8f9cd860cc903c24dc3d896039f492ee8d3c3"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.85)\n",
    "score = []\n",
    "c = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "for i in c:\n",
    "    lsvc = LinearSVC(C=i)\n",
    "    lsvc.fit(X_train, y_train)\n",
    "    score.append(accuracy_score(y_val, lsvc.predict(X_val)))\n",
    "    print (\"Accuracy for C=%s: %s\" % (i, score[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9d4c3d5e871f1366e1864bc0871861c1bdac6044"
   },
   "outputs": [],
   "source": [
    "print(\"Value using for C: \", c[np.where(max(score) == score)[0][0]])\n",
    "final_model = LinearSVC(C=c[np.where(max(score) == score)[0][0]])\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83fcb4d2c09419739fcb4a1919f5bc3db56d79be"
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        lsvc_ngram_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75d7b348909eccaebd6fbff063e683e43bec27e8"
   },
   "outputs": [],
   "source": [
    "pos = [\"I've seen this story before but my kids haven't. Boy with troubled past joins military, faces his past, falls in love and becomes a man. \"\n",
    "       \"The mentor this time is played perfectly by Kevin Costner; An ordinary man with common everyday problems who lives an extraordinary \"\n",
    "       \"conviction, to save lives. After losing his team he takes a teaching position training the next generation of heroes. The young troubled \"\n",
    "       \"recruit is played by Kutcher. While his scenes with the local love interest are a tad stiff and don't generate enough heat to melt butter, \"\n",
    "       \"he compliments Costner well. I never really understood Sela Ward as the neglected wife and felt she should of wanted Costner to quit out of \"\n",
    "       \"concern for his safety as opposed to her selfish needs. But her presence on screen is a pleasure. The two unaccredited stars of this movie \"\n",
    "       \"are the Coast Guard and the Sea. Both powerful forces which should not be taken for granted in real life or this movie. The movie has some \"\n",
    "       \"slow spots and could have used the wasted 15 minutes to strengthen the character relationships. But it still works. The rescue scenes are \"\n",
    "       \"intense and well filmed and edited to provide maximum impact. This movie earns the audience applause. And the applause of my two sons.\"]\n",
    "print(\"Pos prediction: {}\". format(lsvc.predict(lsvc_ngram_vectorizer.transform(pos))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e896da4f0c80379c18541d35eaa1245449c47f45"
   },
   "outputs": [],
   "source": [
    "neg = [\"We do not want to send out an e-mail with a subject line that recipient(s) feel like avoiding.\"\"\n",
    "       \"Think about your own reaction on e-mails with negative subject lines;\"\n",
    "       \"do you even feel like opening them? Example, instead of a subject line that says ‘Delay in\" \n",
    "       \"ABC project schedule,’ the subject line can be ‘Changes in ABC project schedule.'\"]\n",
    "print(\"Neg prediction: {}\". format(lsvc.predict(lsvc_ngram_vectorizer.transform(neg))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b6ee0d1c579a6881ee693614d9084d089d225cef"
   },
   "source": [
    "**Using Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "89248cb664327b470b795cf9bf7f8bb8bb51166c"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "9606dbbc701717125c5a60b02e3f66c73291d03f"
   },
   "outputs": [],
   "source": [
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "no_stop_words_test = remove_stop_words(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "e77f1784243fedc232ec40d5c284c0f1afcf0265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  86357\n"
     ]
    }
   ],
   "source": [
    "stopword_vectorizer = CountVectorizer(binary=True)\n",
    "stopword_vectorizer.fit(no_stop_words_train)\n",
    "print(\"Size of dictionary: \", len(stopword_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", stopword_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "5112384eb2c5c9deeee3eed5be884f3bd93c8af3"
   },
   "outputs": [],
   "source": [
    "X_train = stopword_vectorizer.transform(no_stop_words_train)\n",
    "X_test = stopword_vectorizer.transform(no_stop_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_uuid": "9e29781f73a8d6313947820937298c907cf95487"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': [1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, target, train_size = 0.85)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "parameters = {\n",
    "    'alpha':list(range(1, 10))\n",
    "}\n",
    "clf = GridSearchCV(mnb, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "d41c6d1b548b029db8aac90f2f429011665aeece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  MultinomialNB(alpha=5, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \", clf.best_estimator_)\n",
    "final_model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "52829b7e782119d9a121e7287b26a121b83b7f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.84252\n"
     ]
    }
   ],
   "source": [
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "3edfc3511af9c6685d09b15386be02a826e82af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one', -5.511019995866638)\n",
      "('film', -5.523028145495035)\n",
      "('movie', -5.5252117358478365)\n",
      "('like', -5.789023154218585)\n",
      "('good', -5.915076944702976)\n",
      "('time', -6.006001424253158)\n",
      "('well', -6.022730184042363)\n",
      "('see', -6.037215116963731)\n",
      "('story', -6.045102481796896)\n",
      "('great', -6.049353586399379)\n",
      "\n",
      "\n",
      "\n",
      "('____________________________________', -12.606415993120331)\n",
      "('____insert', -12.606415993120331)\n",
      "('_a', -12.606415993120331)\n",
      "('_absolute', -12.606415993120331)\n",
      "('_am_', -12.606415993120331)\n",
      "('_and_', -12.606415993120331)\n",
      "('_angel_', -12.606415993120331)\n",
      "('_annie_', -12.606415993120331)\n",
      "('_any_', -12.606415993120331)\n",
      "('_anything_', -12.606415993120331)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        stopword_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24f4c7c6952229cd5df57b6e4e45f584cfd692cd"
   },
   "source": [
    "**Using Naive Bayes with TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "d21b94e2cf69ec40007724977725728bf0b2d7d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  1777206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', analyzer='word', ngram_range=(1, 2))\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "print(\"Size of dictionary: \", len(tfidf_vectorizer.get_feature_names()))\n",
    "#print(\"Words in dictionary: \", tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_uuid": "8714c1f2f179b5bd1c0fa0c538b9b19b706104f4"
   },
   "outputs": [],
   "source": [
    "X_train = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_test = tfidf_vectorizer.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_uuid": "9ffc32e0b3d1ec38a8dea331765642f96610d973"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': [1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, target, train_size = 0.85)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "parameters = {\n",
    "    'alpha':list(range(1, 10))\n",
    "}\n",
    "clf = GridSearchCV(mnb, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_uuid": "c71ec7085901f78e5208ecc82146ab49effbbf30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \", clf.best_estimator_)\n",
    "final_model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "_uuid": "9e06dfdc527377dd286440b1c09c7d89ad031515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.85452\n"
     ]
    }
   ],
   "source": [
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f28fed1ac166c2a7472795dccbb377ddf52f627e"
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        tfidf_vectorizer.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1be108329f24abe9f935e4d6e78ec629522f048b"
   },
   "outputs": [],
   "source": [
    "Naive Bayes is a very good algorithm for text classification and considered as baseline. Basically for text classification NB is benchmark where accuracy of other algorithms are compared with NB."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
